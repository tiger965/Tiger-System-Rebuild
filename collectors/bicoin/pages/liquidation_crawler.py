"""
å¸Coinçˆ†ä»“ç»Ÿè®¡çˆ¬è™«
å®æ—¶ç›‘æ§å…¨ç½‘çˆ†ä»“æ•°æ®ï¼Œåˆ†æå¸‚åœºæç«¯æƒ…å†µ
"""

import json
import time
import random
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import logging
import sys
import os
import requests

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from bicoin_auth import BiCoinAuth

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class LiquidationCrawler:
    """çˆ†ä»“æ•°æ®çˆ¬è™«"""
    
    def __init__(self, auth: BiCoinAuth):
        """
        åˆå§‹åŒ–çˆ¬è™«
        
        Args:
            auth: BiCoinAuthå®ä¾‹
        """
        self.auth = auth
        self.driver = auth.get_driver()
        self.api_url = "https://test1.bicoin.info/place-mgr/stock/state"
        self.web_url = "https://i.bicoin.com.cn/web/modules/liquidation.html"
        self.data_path = "data/liquidation/"
        
        # åˆ›å»ºæ•°æ®ç›®å½•
        os.makedirs(self.data_path, exist_ok=True)
        
        # çˆ†ä»“é˜ˆå€¼è®¾ç½®
        self.thresholds = {
            "large_amount": 100000,  # å¤§é¢çˆ†ä»“é˜ˆå€¼ï¼ˆUSDTï¼‰
            "alert_rate": 1000000,   # è­¦æŠ¥çº§åˆ«çˆ†ä»“æ€»é¢ï¼ˆUSDT/å°æ—¶ï¼‰
            "cascade_threshold": 5   # è¿ç»­çˆ†ä»“æ¬¡æ•°é˜ˆå€¼
        }
        
    def get_api_data(self) -> Optional[Dict[str, Any]]:
        """
        é€šè¿‡APIè·å–çˆ†ä»“æ•°æ®
        
        Returns:
            Dict: APIè¿”å›çš„æ•°æ®
        """
        try:
            # ä»driverè·å–cookies
            cookies = self.driver.get_cookies()
            session = requests.Session()
            
            # è®¾ç½®cookies
            for cookie in cookies:
                session.cookies.set(cookie['name'], cookie['value'])
            
            # è®¾ç½®è¯·æ±‚å¤´
            headers = {
                'User-Agent': self.driver.execute_script("return navigator.userAgent"),
                'Referer': 'https://i.bicoin.com.cn',
                'Accept': 'application/json, text/plain, */*'
            }
            
            # å‘é€è¯·æ±‚
            response = session.get(self.api_url, headers=headers, timeout=10)
            
            if response.status_code == 200:
                return response.json()
            else:
                logger.warning(f"APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                return None
                
        except Exception as e:
            logger.error(f"è·å–APIæ•°æ®å¤±è´¥: {e}")
            return None
    
    def crawl_web_data(self) -> Dict[str, Any]:
        """
        ä»ç½‘é¡µçˆ¬å–çˆ†ä»“æ•°æ®
        
        Returns:
            Dict: çˆ†ä»“æ•°æ®
        """
        liquidation_data = {
            "crawl_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "summary": {},
            "recent_liquidations": [],
            "statistics": {}
        }
        
        try:
            # è®¿é—®çˆ†ä»“é¡µé¢
            logger.info(f"è®¿é—®çˆ†ä»“ç»Ÿè®¡é¡µé¢: {self.web_url}")
            self.driver.get(self.web_url)
            
            # ç­‰å¾…é¡µé¢åŠ è½½
            wait = WebDriverWait(self.driver, 20)
            wait.until(EC.presence_of_element_located((By.CLASS_NAME, "liquidation-container")))
            
            time.sleep(3)
            
            # è·å–æ±‡æ€»æ•°æ®
            liquidation_data["summary"] = self._get_summary_data()
            
            # è·å–æœ€è¿‘çˆ†ä»“åˆ—è¡¨
            liquidation_data["recent_liquidations"] = self._get_recent_liquidations()
            
            # è·å–ç»Ÿè®¡æ•°æ®
            liquidation_data["statistics"] = self._get_statistics()
            
            # åˆ†æçˆ†ä»“è¶‹åŠ¿
            liquidation_data["analysis"] = self._analyze_liquidations(liquidation_data)
            
            return liquidation_data
            
        except TimeoutException:
            logger.error("é¡µé¢åŠ è½½è¶…æ—¶")
            return liquidation_data
        except Exception as e:
            logger.error(f"çˆ¬å–ç½‘é¡µæ•°æ®å¤±è´¥: {e}")
            return liquidation_data
    
    def _get_summary_data(self) -> Dict[str, Any]:
        """è·å–çˆ†ä»“æ±‡æ€»æ•°æ®"""
        summary = {
            "total_24h": 0,
            "total_1h": 0,
            "long_liquidations": 0,
            "short_liquidations": 0,
            "long_percentage": 0,
            "short_percentage": 0,
            "largest_single": 0
        }
        
        try:
            # 24å°æ—¶çˆ†ä»“æ€»é¢
            try:
                total_24h = self.driver.find_element(By.CLASS_NAME, "total-24h").text
                summary["total_24h"] = self._parse_amount(total_24h)
            except:
                pass
            
            # 1å°æ—¶çˆ†ä»“æ€»é¢
            try:
                total_1h = self.driver.find_element(By.CLASS_NAME, "total-1h").text
                summary["total_1h"] = self._parse_amount(total_1h)
            except:
                pass
            
            # å¤šç©ºçˆ†ä»“æ•°æ®
            try:
                long_amount = self.driver.find_element(By.CLASS_NAME, "long-liquidation").text
                summary["long_liquidations"] = self._parse_amount(long_amount)
                
                short_amount = self.driver.find_element(By.CLASS_NAME, "short-liquidation").text
                summary["short_liquidations"] = self._parse_amount(short_amount)
                
                # è®¡ç®—ç™¾åˆ†æ¯”
                total = summary["long_liquidations"] + summary["short_liquidations"]
                if total > 0:
                    summary["long_percentage"] = (summary["long_liquidations"] / total) * 100
                    summary["short_percentage"] = (summary["short_liquidations"] / total) * 100
            except:
                pass
            
            # æœ€å¤§å•ç¬”çˆ†ä»“
            try:
                largest = self.driver.find_element(By.CLASS_NAME, "largest-liquidation").text
                summary["largest_single"] = self._parse_amount(largest)
            except:
                pass
            
        except Exception as e:
            logger.error(f"è·å–æ±‡æ€»æ•°æ®å¤±è´¥: {e}")
        
        return summary
    
    def _get_recent_liquidations(self, limit: int = 50) -> List[Dict[str, Any]]:
        """è·å–æœ€è¿‘çš„çˆ†ä»“è®°å½•"""
        liquidations = []
        
        try:
            # è·å–çˆ†ä»“åˆ—è¡¨
            items = self.driver.find_elements(By.CLASS_NAME, "liquidation-item")[:limit]
            
            for item in items:
                try:
                    liq_data = {}
                    
                    # äº¤æ˜“æ‰€
                    try:
                        exchange = item.find_element(By.CLASS_NAME, "exchange").text
                        liq_data["exchange"] = exchange
                    except:
                        liq_data["exchange"] = "Unknown"
                    
                    # äº¤æ˜“å¯¹
                    try:
                        symbol = item.find_element(By.CLASS_NAME, "symbol").text
                        liq_data["symbol"] = symbol
                    except:
                        liq_data["symbol"] = "Unknown"
                    
                    # æ–¹å‘
                    try:
                        direction = item.find_element(By.CLASS_NAME, "direction").text
                        liq_data["direction"] = "LONG" if "å¤š" in direction else "SHORT"
                    except:
                        liq_data["direction"] = "Unknown"
                    
                    # çˆ†ä»“é‡‘é¢
                    try:
                        amount = item.find_element(By.CLASS_NAME, "amount").text
                        liq_data["amount"] = self._parse_amount(amount)
                    except:
                        liq_data["amount"] = 0
                    
                    # çˆ†ä»“ä»·æ ¼
                    try:
                        price = item.find_element(By.CLASS_NAME, "price").text
                        liq_data["price"] = float(price.replace(",", "").replace("$", ""))
                    except:
                        liq_data["price"] = 0
                    
                    # æ—¶é—´
                    try:
                        time_text = item.find_element(By.CLASS_NAME, "time").text
                        liq_data["time"] = time_text
                    except:
                        liq_data["time"] = ""
                    
                    if liq_data["amount"] > 0:
                        liquidations.append(liq_data)
                    
                except Exception as e:
                    logger.debug(f"è§£æçˆ†ä»“è®°å½•å¤±è´¥: {e}")
                    continue
            
        except Exception as e:
            logger.error(f"è·å–çˆ†ä»“åˆ—è¡¨å¤±è´¥: {e}")
        
        return liquidations
    
    def _get_statistics(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡æ•°æ®"""
        stats = {
            "by_exchange": {},
            "by_symbol": {},
            "by_time": {},
            "trends": {}
        }
        
        try:
            # äº¤æ˜“æ‰€åˆ†å¸ƒ
            exchange_items = self.driver.find_elements(By.CLASS_NAME, "exchange-stat")
            for item in exchange_items[:10]:
                try:
                    name = item.find_element(By.CLASS_NAME, "name").text
                    value = item.find_element(By.CLASS_NAME, "value").text
                    stats["by_exchange"][name] = self._parse_amount(value)
                except:
                    continue
            
            # å¸ç§åˆ†å¸ƒ
            symbol_items = self.driver.find_elements(By.CLASS_NAME, "symbol-stat")
            for item in symbol_items[:10]:
                try:
                    name = item.find_element(By.CLASS_NAME, "name").text
                    value = item.find_element(By.CLASS_NAME, "value").text
                    stats["by_symbol"][name] = self._parse_amount(value)
                except:
                    continue
            
        except Exception as e:
            logger.error(f"è·å–ç»Ÿè®¡æ•°æ®å¤±è´¥: {e}")
        
        return stats
    
    def _parse_amount(self, amount_str: str) -> float:
        """
        è§£æé‡‘é¢å­—ç¬¦ä¸²
        
        Args:
            amount_str: é‡‘é¢å­—ç¬¦ä¸²ï¼ˆå¯èƒ½åŒ…å«K, M, Bç­‰å•ä½ï¼‰
            
        Returns:
            float: é‡‘é¢æ•°å€¼
        """
        try:
            # æ¸…ç†å­—ç¬¦ä¸²
            amount_str = amount_str.replace(",", "").replace("$", "").replace("USDT", "").strip()
            
            # å¤„ç†å•ä½
            if "K" in amount_str or "k" in amount_str:
                return float(amount_str.replace("K", "").replace("k", "")) * 1000
            elif "M" in amount_str or "m" in amount_str:
                return float(amount_str.replace("M", "").replace("m", "")) * 1000000
            elif "B" in amount_str or "b" in amount_str:
                return float(amount_str.replace("B", "").replace("b", "")) * 1000000000
            else:
                return float(amount_str)
        except:
            return 0
    
    def _analyze_liquidations(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        åˆ†æçˆ†ä»“æ•°æ®
        
        Args:
            data: çˆ†ä»“æ•°æ®
            
        Returns:
            Dict: åˆ†æç»“æœ
        """
        analysis = {
            "market_status": "NORMAL",
            "risk_level": "LOW",
            "dominant_direction": "NEUTRAL",
            "large_liquidations": [],
            "warnings": [],
            "signals": []
        }
        
        summary = data.get("summary", {})
        recent = data.get("recent_liquidations", [])
        
        # åˆ¤æ–­å¸‚åœºçŠ¶æ€
        total_1h = summary.get("total_1h", 0)
        if total_1h > self.thresholds["alert_rate"]:
            analysis["market_status"] = "EXTREME"
            analysis["risk_level"] = "HIGH"
            analysis["warnings"].append(f"çˆ†ä»“é€Ÿç‡å¼‚å¸¸: {total_1h/1000000:.2f}M USDT/å°æ—¶")
        elif total_1h > self.thresholds["alert_rate"] / 2:
            analysis["market_status"] = "VOLATILE"
            analysis["risk_level"] = "MEDIUM"
        
        # åˆ¤æ–­çˆ†ä»“æ–¹å‘
        long_pct = summary.get("long_percentage", 50)
        if long_pct > 70:
            analysis["dominant_direction"] = "SHORT_SQUEEZE"
            analysis["signals"].append("ç©ºå¤´ä¸»å¯¼ï¼Œå¯èƒ½è§åº•")
        elif long_pct < 30:
            analysis["dominant_direction"] = "LONG_SQUEEZE"
            analysis["signals"].append("å¤šå¤´ä¸»å¯¼ï¼Œå¯èƒ½è§é¡¶")
        
        # è¯†åˆ«å¤§é¢çˆ†ä»“
        for liq in recent:
            if liq.get("amount", 0) > self.thresholds["large_amount"]:
                analysis["large_liquidations"].append({
                    "exchange": liq.get("exchange"),
                    "symbol": liq.get("symbol"),
                    "amount": liq.get("amount"),
                    "direction": liq.get("direction")
                })
        
        # æ£€æµ‹è¿ç»­çˆ†ä»“ï¼ˆcascade)
        if len(recent) >= self.thresholds["cascade_threshold"]:
            same_direction = all(
                liq.get("direction") == recent[0].get("direction") 
                for liq in recent[:self.thresholds["cascade_threshold"]]
            )
            if same_direction:
                direction = recent[0].get("direction")
                analysis["warnings"].append(f"æ£€æµ‹åˆ°{direction}è¿ç»­çˆ†ä»“ï¼Œå¯èƒ½å‡ºç°è¸©è¸")
        
        # ç”Ÿæˆäº¤æ˜“ä¿¡å·
        if analysis["risk_level"] == "HIGH":
            if analysis["dominant_direction"] == "LONG_SQUEEZE":
                analysis["signals"].append("è€ƒè™‘å‡ä»“æˆ–åšç©º")
            elif analysis["dominant_direction"] == "SHORT_SQUEEZE":
                analysis["signals"].append("è€ƒè™‘é€¢ä½ä¹°å…¥")
        
        return analysis
    
    def monitor_realtime(self, interval: int = 60, duration: int = 3600):
        """
        å®æ—¶ç›‘æ§çˆ†ä»“æ•°æ®
        
        Args:
            interval: æ›´æ–°é—´éš”ï¼ˆç§’ï¼‰
            duration: ç›‘æ§æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
        """
        start_time = time.time()
        historical_data = []
        
        logger.info(f"å¼€å§‹å®æ—¶ç›‘æ§çˆ†ä»“ï¼Œé—´éš”{interval}ç§’ï¼ŒæŒç»­{duration/3600}å°æ—¶")
        
        while time.time() - start_time < duration:
            try:
                # è·å–æ•°æ®ï¼ˆä¼˜å…ˆAPIï¼Œå¤‡ç”¨ç½‘é¡µï¼‰
                api_data = self.get_api_data()
                
                if api_data:
                    logger.info("ä½¿ç”¨APIæ•°æ®")
                    current_data = self._process_api_data(api_data)
                else:
                    logger.info("ä½¿ç”¨ç½‘é¡µæ•°æ®")
                    current_data = self.crawl_web_data()
                
                # æ·»åŠ åˆ°å†å²æ•°æ®
                historical_data.append(current_data)
                
                # ä¿å­˜æ•°æ®
                self._save_data(current_data)
                
                # åˆ†æå¹¶è¾“å‡º
                analysis = current_data.get("analysis", {})
                summary = current_data.get("summary", {})
                
                logger.info(f"\n===== çˆ†ä»“ç›‘æ§ =====")
                logger.info(f"1å°æ—¶çˆ†ä»“: {summary.get('total_1h', 0)/1000000:.2f}M USDT")
                logger.info(f"24å°æ—¶çˆ†ä»“: {summary.get('total_24h', 0)/1000000:.2f}M USDT")
                logger.info(f"å¤šç©ºæ¯”: {summary.get('long_percentage', 0):.1f}% : {summary.get('short_percentage', 0):.1f}%")
                logger.info(f"å¸‚åœºçŠ¶æ€: {analysis.get('market_status', 'UNKNOWN')}")
                logger.info(f"é£é™©ç­‰çº§: {analysis.get('risk_level', 'UNKNOWN')}")
                
                # è¾“å‡ºè­¦å‘Š
                for warning in analysis.get("warnings", []):
                    logger.warning(f"âš ï¸ {warning}")
                
                # è¾“å‡ºä¿¡å·
                for signal in analysis.get("signals", []):
                    logger.info(f"ğŸ“Š {signal}")
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦æŠ¥è­¦
                if analysis.get("risk_level") == "HIGH":
                    self._send_alert(current_data)
                
                # ç­‰å¾…ä¸‹æ¬¡æ›´æ–°
                if time.time() - start_time < duration:
                    time.sleep(interval)
                    
            except Exception as e:
                logger.error(f"ç›‘æ§å‡ºé”™: {e}")
                time.sleep(30)
        
        logger.info("ç›‘æ§ç»“æŸ")
        
        # ç”Ÿæˆç›‘æ§æŠ¥å‘Š
        self._generate_report(historical_data)
    
    def _process_api_data(self, api_data: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†APIæ•°æ®æ ¼å¼"""
        # æ ¹æ®å®é™…APIè¿”å›æ ¼å¼è¿›è¡Œå¤„ç†
        processed = {
            "crawl_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "summary": {},
            "recent_liquidations": [],
            "statistics": {}
        }
        
        # TODO: æ ¹æ®å®é™…APIæ ¼å¼è§£ææ•°æ®
        
        return processed
    
    def _save_data(self, data: Dict[str, Any]):
        """ä¿å­˜æ•°æ®"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{self.data_path}liquidation_{timestamp}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        logger.debug(f"æ•°æ®å·²ä¿å­˜: {filename}")
    
    def _send_alert(self, data: Dict[str, Any]):
        """å‘é€è­¦æŠ¥ï¼ˆè¿™é‡Œåªæ˜¯æ—¥å¿—ï¼Œå®é™…å¯æ¥å…¥é€šçŸ¥ç³»ç»Ÿï¼‰"""
        logger.critical("ğŸš¨ çˆ†ä»“è­¦æŠ¥ ğŸš¨")
        logger.critical(f"é£é™©ç­‰çº§: {data['analysis']['risk_level']}")
        logger.critical(f"1å°æ—¶çˆ†ä»“: {data['summary']['total_1h']/1000000:.2f}M USDT")
        
    def _generate_report(self, historical_data: List[Dict[str, Any]]):
        """ç”Ÿæˆç›‘æ§æŠ¥å‘Š"""
        if not historical_data:
            return
        
        report = {
            "monitoring_period": {
                "start": historical_data[0]["crawl_time"],
                "end": historical_data[-1]["crawl_time"],
                "data_points": len(historical_data)
            },
            "summary": {
                "total_liquidations": sum(d["summary"].get("total_1h", 0) for d in historical_data),
                "avg_hourly": sum(d["summary"].get("total_1h", 0) for d in historical_data) / len(historical_data),
                "max_hourly": max(d["summary"].get("total_1h", 0) for d in historical_data),
                "high_risk_periods": sum(1 for d in historical_data if d["analysis"].get("risk_level") == "HIGH")
            }
        }
        
        # ä¿å­˜æŠ¥å‘Š
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = f"{self.data_path}report_{timestamp}.json"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ç›‘æ§æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    # åˆå§‹åŒ–è®¤è¯
    auth = BiCoinAuth()
    
    # ç™»å½•
    if auth.login():
        # åˆ›å»ºçˆ¬è™«
        crawler = LiquidationCrawler(auth)
        
        # çˆ¬å–çˆ†ä»“æ•°æ®
        data = crawler.crawl_web_data()
        
        if data:
            print(f"\nçˆ†ä»“æ•°æ®:")
            print(f"1å°æ—¶çˆ†ä»“: {data['summary'].get('total_1h', 0)/1000000:.2f}M USDT")
            print(f"24å°æ—¶çˆ†ä»“: {data['summary'].get('total_24h', 0)/1000000:.2f}M USDT")
            print(f"å¤šç©ºæ¯”: {data['summary'].get('long_percentage', 0):.1f}% : {data['summary'].get('short_percentage', 0):.1f}%")
            print(f"å¸‚åœºçŠ¶æ€: {data['analysis'].get('market_status')}")
            print(f"é£é™©ç­‰çº§: {data['analysis'].get('risk_level')}")
        
        # å…³é—­
        auth.close()
    else:
        print("ç™»å½•å¤±è´¥")