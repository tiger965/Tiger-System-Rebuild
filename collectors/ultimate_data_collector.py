"""
Window 3 - ç»ˆææ•°æ®æ”¶é›†å™¨
æ•´åˆå‰ä»»ç•™ä¸‹çš„æ‰€æœ‰æœ‰ä»·å€¼çš„æ•°æ®æº
è¿™æ˜¯Window 3çš„æ ¸å¿ƒ - å…¨æ–¹ä½æƒ…æŠ¥æ”¶é›†ç³»ç»Ÿ
"""

import asyncio
import aiohttp
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional

# å¯¼å…¥æ‰€æœ‰æœ‰ä»·å€¼çš„æ”¶é›†å™¨
try:
    from free_api_aggregator import FreeApiAggregator
    from blockchain.multi_chain_monitor import MultiChainMonitor
    from blockchain.whale_tracker import WhaleTracker
    from blockchain.defi_monitor import DeFiMonitor
    from blockchain.gas_monitor import GasMonitor
    from blockchain.exchange_wallet_monitor import ExchangeWalletMonitor
    from defi.defi_monitor import DeFiMonitor as DeFiEcosystem
    from signal_aggregator.valuescan_crawler import ValueScanCrawler
    from bicoin.integrated_monitor import IntegratedMonitor as BiCoinMonitor
    from news.news_analyzer import NewsAnalyzer
    from chain_social.early_warning import EarlyWarningSystem
    from macro.macro_monitor import MacroMonitor
    from composite_signal_monitor import CompositeSignalMonitor
except ImportError as e:
    print(f"éƒ¨åˆ†æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")

logger = logging.getLogger(__name__)


class UltimateDataCollector:
    """
    ç»ˆææ•°æ®æ”¶é›†å™¨
    æ•´åˆæ‰€æœ‰æ•°æ®æºï¼Œæä¾›å…¨æ–¹ä½çš„å¸‚åœºæƒ…æŠ¥
    """
    
    def __init__(self):
        logger.info("=" * 60)
        logger.info("Window 3 - ç»ˆææ•°æ®æ”¶é›†å™¨åˆå§‹åŒ–")
        logger.info("æ•´åˆæ‰€æœ‰å…è´¹å’Œä»˜è´¹æ•°æ®æº")
        logger.info("=" * 60)
        
        # åˆå§‹åŒ–æ‰€æœ‰æ”¶é›†å™¨
        self.collectors = {
            "free_apis": FreeApiAggregator(),
            "multi_chain": None,  # å°†å»¶è¿Ÿåˆå§‹åŒ–
            "whale_tracker": None,
            "defi_monitor": None,
            "gas_monitor": None,
            "exchange_wallets": None,
            "valuescan": None,
            "bicoin": None,
            "news": None,
            "social": None,
            "macro": None,
            "composite": None
        }
        
        # æ•°æ®æºæ¸…å•
        self.data_sources = {
            # å…è´¹å…¬é“¾RPCï¼ˆ14æ¡ä¸»é“¾ï¼‰
            "chain_rpcs": [
                "Ethereum", "BSC", "Polygon", "Avalanche", "Arbitrum",
                "Optimism", "Fantom", "Solana", "Tron", "Near",
                "Cosmos", "Base", "zkSync", "Linea"
            ],
            
            # å…è´¹åŒºå—é“¾æµè§ˆå™¨API
            "explorers": [
                "Etherscan", "BscScan", "PolygonScan", "FTMScan",
                "SnowTrace", "Arbiscan", "Optimistic", "BaseScan"
            ],
            
            # å…è´¹DeFiæ•°æ®
            "defi": [
                "DefiLlama", "DexScreener", "GeckoTerminal",
                "1inch API", "OpenOcean", "0x API"
            ],
            
            # å…è´¹ä»·æ ¼æ•°æ®
            "price": [
                "CoinGecko", "CoinPaprika", "Messari",
                "CoinMarketCap (limited)", "CryptoCompare"
            ],
            
            # å…è´¹é“¾ä¸Šæ•°æ®
            "onchain": [
                "Blockchair", "Blockchain.info", "EthGasStation",
                "GasNow", "Mempool.space", "BlockCypher"
            ],
            
            # å…è´¹NFTæ•°æ®
            "nft": [
                "OpenSea", "Reservoir", "NFTScan", "Alchemy NFT API"
            ],
            
            # å…è´¹ç¤¾äº¤/æƒ…ç»ª
            "social": [
                "Alternative.me (Fear & Greed)", "LunarCrush (limited)",
                "Santiment (limited)", "Google Trends API"
            ],
            
            # ä»˜è´¹APIï¼ˆå·²è´­ä¹°ï¼‰
            "paid": [
                "WhaleAlert Personal ($29.95/æœˆ)",
                "CryptoPanic Professional (é…é¢å·²ç”¨å®Œ)",
                "Coinglass Hobbyist (35 USDT/æœˆ)"
            ],
            
            # éœ€è¦çˆ¬è™«çš„ç½‘ç«™
            "crawlers": [
                "ValueScan.io", "å¸Coin", "Twitter", "Reddit",
                "å„å¤§äº¤æ˜“æ‰€å…¬å‘Š", "é¡¹ç›®Discord/Telegram"
            ]
        }
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "total_sources": len(self.data_sources),
            "active_chains": 14,
            "defi_protocols": 100,
            "data_points_per_minute": 0,
            "api_calls_made": 0,
            "errors": 0
        }

    async def initialize_all_collectors(self):
        """åˆå§‹åŒ–æ‰€æœ‰æ”¶é›†å™¨"""
        logger.info("åˆå§‹åŒ–æ‰€æœ‰æ•°æ®æ”¶é›†å™¨...")
        
        try:
            # åˆå§‹åŒ–å„ä¸ªæ”¶é›†å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            try:
                from blockchain.multi_chain_monitor import MultiChainMonitor
                self.collectors["multi_chain"] = MultiChainMonitor()
            except:
                logger.warning("MultiChainMonitorä¸å¯ç”¨")
            
            try:
                from blockchain.whale_tracker import WhaleTracker
                self.collectors["whale_tracker"] = WhaleTracker()
            except:
                logger.warning("WhaleTrackerä¸å¯ç”¨")
            
            # ... åˆå§‹åŒ–å…¶ä»–æ”¶é›†å™¨
            
            logger.info(f"æˆåŠŸåˆå§‹åŒ– {sum(1 for c in self.collectors.values() if c)} ä¸ªæ”¶é›†å™¨")
            
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–æ”¶é›†å™¨å¤±è´¥: {e}")

    async def collect_all_chain_data(self) -> Dict:
        """
        æ”¶é›†æ‰€æœ‰åŒºå—é“¾æ•°æ®
        åŒ…æ‹¬14æ¡ä¸»é“¾çš„å®æ—¶æ•°æ®
        """
        all_chain_data = {}
        
        # 1. ä½¿ç”¨å…è´¹APIèšåˆå™¨è·å–å¤šé“¾æ•°æ®
        free_aggregator = self.collectors["free_apis"]
        chain_data = await free_aggregator.get_multi_chain_data()
        all_chain_data["basic_chain_data"] = chain_data
        
        # 2. è·å–DeFi TVLæ•°æ®
        defi_tvl = await free_aggregator.get_defi_tvl_data()
        all_chain_data["defi_tvl"] = defi_tvl
        
        # 3. è·å–DEXæ•°æ®
        dex_data = await free_aggregator.get_dex_data()
        all_chain_data["dex_volume"] = dex_data
        
        # 4. è·å–Gasä»·æ ¼
        gas_prices = await free_aggregator.get_gas_prices()
        all_chain_data["gas_prices"] = gas_prices
        
        # 5. è·å–ç¨³å®šå¸æ•°æ®
        stablecoin_data = await free_aggregator.get_stablecoin_data()
        all_chain_data["stablecoins"] = stablecoin_data
        
        # 6. è·å–å†…å­˜æ± æ•°æ®
        mempool_data = await free_aggregator.get_mempool_data()
        all_chain_data["mempool"] = mempool_data
        
        self.stats["api_calls_made"] += 6
        
        return all_chain_data

    async def collect_whale_data(self) -> Dict:
        """
        æ”¶é›†å·¨é²¸æ•°æ®
        ä½¿ç”¨WhaleAlert APIå’Œé“¾ä¸Šæ•°æ®
        """
        whale_data = {}
        
        try:
            # WhaleAlert APIï¼ˆä»˜è´¹ï¼‰
            whale_alert_key = "pGV9OtVnzgp0bTbUgU4aaWhVMVYfqPLU"
            
            async with aiohttp.ClientSession() as session:
                url = "https://api.whale-alert.io/v1/transactions"
                headers = {"X-WA-API-KEY": whale_alert_key}
                params = {
                    "api_key": whale_alert_key,
                    "min_value": 100000,  # 10ä¸‡ç¾å…ƒä»¥ä¸Š
                    "limit": 100
                }
                
                async with session.get(url, headers=headers, params=params) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        whale_data["whale_alert"] = data.get("transactions", [])
                    
            self.stats["api_calls_made"] += 1
            
        except Exception as e:
            logger.error(f"æ”¶é›†å·¨é²¸æ•°æ®å¤±è´¥: {e}")
            self.stats["errors"] += 1
        
        return whale_data

    async def collect_social_sentiment(self) -> Dict:
        """
        æ”¶é›†ç¤¾äº¤æƒ…ç»ªæ•°æ®
        åŒ…æ‹¬ææ…Œè´ªå©ªæŒ‡æ•°ã€ç¤¾äº¤åª’ä½“æƒ…ç»ªç­‰
        """
        sentiment_data = {}
        
        # 1. ææ…Œè´ªå©ªæŒ‡æ•°
        free_aggregator = self.collectors["free_apis"]
        fear_greed = await free_aggregator.get_fear_greed_index()
        sentiment_data["fear_greed"] = fear_greed
        
        # 2. çƒ­é—¨ä»£å¸
        trending = await free_aggregator.get_trending_tokens()
        sentiment_data["trending"] = trending
        
        self.stats["api_calls_made"] += 2
        
        return sentiment_data

    async def collect_exchange_data(self) -> Dict:
        """
        æ”¶é›†äº¤æ˜“æ‰€æ•°æ®
        åŒ…æ‹¬å…¬å¼€çš„äº¤æ˜“æ‰€APIæ•°æ®
        """
        exchange_data = {}
        
        exchanges = {
            "binance": "https://api.binance.com/api/v3",
            "okx": "https://www.okx.com/api/v5",
            "coinbase": "https://api.exchange.coinbase.com",
            "kraken": "https://api.kraken.com/0",
            "kucoin": "https://api.kucoin.com/api/v1"
        }
        
        async with aiohttp.ClientSession() as session:
            # è·å–BTCä»·æ ¼ä½œä¸ºç¤ºä¾‹
            for name, base_url in exchanges.items():
                try:
                    if name == "binance":
                        url = f"{base_url}/ticker/price?symbol=BTCUSDT"
                    elif name == "okx":
                        url = f"{base_url}/market/ticker?instId=BTC-USDT"
                    else:
                        continue  # ç®€åŒ–ç¤ºä¾‹
                    
                    async with session.get(url, timeout=5) as resp:
                        if resp.status == 200:
                            data = await resp.json()
                            exchange_data[name] = data
                            
                except Exception as e:
                    logger.error(f"è·å–{name}æ•°æ®å¤±è´¥: {e}")
        
        self.stats["api_calls_made"] += len(exchanges)
        
        return exchange_data

    async def collect_defi_ecosystem(self) -> Dict:
        """
        æ”¶é›†å®Œæ•´çš„DeFiç”Ÿæ€ç³»ç»Ÿæ•°æ®
        """
        defi_data = {}
        
        # DefiLlamaå®Œæ•´æ•°æ®
        endpoints = {
            "protocols": "https://api.llama.fi/protocols",
            "chains": "https://api.llama.fi/chains",
            "pools": "https://api.llama.fi/pools",
            "stablecoins": "https://api.llama.fi/stablecoins",
            "dexs": "https://api.llama.fi/overview/dexs",
            "fees": "https://api.llama.fi/overview/fees",
            "options": "https://api.llama.fi/overview/options",
            "derivatives": "https://api.llama.fi/overview/derivatives"
        }
        
        async with aiohttp.ClientSession() as session:
            for key, url in endpoints.items():
                try:
                    async with session.get(url, timeout=10) as resp:
                        if resp.status == 200:
                            defi_data[key] = await resp.json()
                except Exception as e:
                    logger.error(f"è·å–DeFi {key}æ•°æ®å¤±è´¥: {e}")
        
        self.stats["api_calls_made"] += len(endpoints)
        
        return defi_data

    async def generate_intelligence_report(self, all_data: Dict) -> Dict:
        """
        ç”Ÿæˆç»¼åˆæƒ…æŠ¥æŠ¥å‘Š
        æ•´åˆæ‰€æœ‰æ•°æ®æºï¼Œæä¾›å…¨æ–¹ä½å¸‚åœºæ´å¯Ÿ
        """
        report = {
            "timestamp": datetime.now().isoformat(),
            "report_id": f"W3_INTEL_{int(datetime.now().timestamp())}",
            
            # æ•°æ®æºç»Ÿè®¡
            "data_sources": {
                "total_sources": self.stats["total_sources"],
                "active_chains": self.stats["active_chains"],
                "api_calls": self.stats["api_calls_made"],
                "errors": self.stats["errors"]
            },
            
            # å¸‚åœºæ¦‚è§ˆ
            "market_overview": {
                "sentiment": self.analyze_market_sentiment(all_data),
                "risk_level": self.assess_risk_level(all_data),
                "opportunities": self.identify_opportunities(all_data),
                "warnings": self.generate_warnings(all_data)
            },
            
            # é“¾ä¸Šæ´»åŠ¨
            "onchain_activity": {
                "active_chains": self.get_active_chains(all_data),
                "gas_trends": self.analyze_gas_trends(all_data),
                "whale_activity": self.analyze_whale_activity(all_data),
                "defi_flows": self.analyze_defi_flows(all_data)
            },
            
            # åŸå§‹æ•°æ®
            "raw_data": all_data,
            
            # æ•°æ®è´¨é‡
            "data_quality": {
                "completeness": self.calculate_completeness(all_data),
                "freshness": self.check_data_freshness(all_data),
                "reliability": self.assess_reliability()
            }
        }
        
        return report

    def analyze_market_sentiment(self, data: Dict) -> str:
        """åˆ†æå¸‚åœºæƒ…ç»ª"""
        # åŸºäºææ…Œè´ªå©ªæŒ‡æ•°å’Œå…¶ä»–æŒ‡æ ‡
        fear_greed = data.get("social_sentiment", {}).get("fear_greed", {}).get("value", 50)
        
        if fear_greed < 25:
            return "extreme_fear"
        elif fear_greed < 45:
            return "fear"
        elif fear_greed < 55:
            return "neutral"
        elif fear_greed < 75:
            return "greed"
        else:
            return "extreme_greed"

    def assess_risk_level(self, data: Dict) -> str:
        """è¯„ä¼°é£é™©ç­‰çº§"""
        # åŸºäºå¤šä¸ªæŒ‡æ ‡ç»¼åˆè¯„ä¼°
        sentiment = self.analyze_market_sentiment(data)
        
        risk_map = {
            "extreme_fear": "low",
            "fear": "medium_low",
            "neutral": "medium",
            "greed": "medium_high",
            "extreme_greed": "high"
        }
        
        return risk_map.get(sentiment, "medium")

    def identify_opportunities(self, data: Dict) -> List[Dict]:
        """è¯†åˆ«æœºä¼š"""
        opportunities = []
        
        # æ£€æŸ¥DeFiæ”¶ç›Šæœºä¼š
        defi_data = data.get("defi_ecosystem", {})
        if defi_data.get("pools"):
            # æ‰¾é«˜æ”¶ç›Šæ± 
            pass
        
        # æ£€æŸ¥å¥—åˆ©æœºä¼š
        exchange_data = data.get("exchange_data", {})
        if exchange_data:
            # è®¡ç®—ä»·å·®
            pass
        
        return opportunities

    def generate_warnings(self, data: Dict) -> List[str]:
        """ç”Ÿæˆè­¦å‘Š"""
        warnings = []
        
        # æ£€æŸ¥Gasä»·æ ¼
        gas_data = data.get("chain_data", {}).get("gas_prices", {})
        if gas_data.get("ethereum", {}).get("fast", 0) > 100:
            warnings.append("ETH Gasä»·æ ¼è¿‡é«˜")
        
        # æ£€æŸ¥å·¨é²¸æ´»åŠ¨
        whale_data = data.get("whale_data", {})
        if whale_data:
            large_transfers = [t for t in whale_data.get("whale_alert", []) 
                             if t.get("amount_usd", 0) > 10000000]
            if large_transfers:
                warnings.append(f"å‘ç°{len(large_transfers)}ç¬”åƒä¸‡ç¾å…ƒçº§å·¨é²¸è½¬è´¦")
        
        return warnings

    def get_active_chains(self, data: Dict) -> List[str]:
        """è·å–æ´»è·ƒçš„é“¾"""
        chain_data = data.get("chain_data", {}).get("basic_chain_data", {})
        return list(chain_data.keys())

    def analyze_gas_trends(self, data: Dict) -> Dict:
        """åˆ†æGasè¶‹åŠ¿"""
        gas_prices = data.get("chain_data", {}).get("gas_prices", {})
        return {
            "ethereum": gas_prices.get("ethereum", {}),
            "trend": "stable"  # éœ€è¦å†å²æ•°æ®å¯¹æ¯”
        }

    def analyze_whale_activity(self, data: Dict) -> Dict:
        """åˆ†æå·¨é²¸æ´»åŠ¨"""
        whale_data = data.get("whale_data", {}).get("whale_alert", [])
        
        total_volume = sum(t.get("amount_usd", 0) for t in whale_data)
        exchange_inflow = sum(t.get("amount_usd", 0) for t in whale_data 
                            if "exchange" in t.get("to", {}).get("owner", "").lower())
        exchange_outflow = sum(t.get("amount_usd", 0) for t in whale_data 
                             if "exchange" in t.get("from", {}).get("owner", "").lower())
        
        return {
            "total_volume": total_volume,
            "exchange_inflow": exchange_inflow,
            "exchange_outflow": exchange_outflow,
            "net_flow": exchange_inflow - exchange_outflow
        }

    def analyze_defi_flows(self, data: Dict) -> Dict:
        """åˆ†æDeFièµ„é‡‘æµ"""
        defi_data = data.get("chain_data", {}).get("defi_tvl", {})
        
        return {
            "total_tvl": defi_data.get("total_tvl", 0),
            "top_protocols": defi_data.get("top_protocols", [])[:5]
        }

    def calculate_completeness(self, data: Dict) -> float:
        """è®¡ç®—æ•°æ®å®Œæ•´åº¦"""
        expected_keys = ["chain_data", "whale_data", "social_sentiment", 
                        "exchange_data", "defi_ecosystem"]
        present_keys = sum(1 for key in expected_keys if key in data and data[key])
        return present_keys / len(expected_keys)

    def check_data_freshness(self, data: Dict) -> str:
        """æ£€æŸ¥æ•°æ®æ–°é²œåº¦"""
        # ç®€åŒ–ç‰ˆæœ¬ï¼Œå®é™…éœ€è¦æ£€æŸ¥æ¯ä¸ªæ•°æ®æºçš„æ—¶é—´æˆ³
        return "fresh"

    def assess_reliability(self) -> float:
        """è¯„ä¼°å¯é æ€§"""
        if self.stats["errors"] == 0:
            return 1.0
        error_rate = self.stats["errors"] / max(self.stats["api_calls_made"], 1)
        return max(0, 1 - error_rate)

    async def run_complete_collection(self) -> Dict:
        """
        è¿è¡Œå®Œæ•´çš„æ•°æ®æ”¶é›†
        è¿™æ˜¯Window 3çš„æ ¸å¿ƒåŠŸèƒ½ - ä¸€æ¬¡è°ƒç”¨è·å–æ‰€æœ‰æ•°æ®
        """
        logger.info("=" * 60)
        logger.info("å¼€å§‹å…¨æ–¹ä½æ•°æ®æ”¶é›†...")
        logger.info(f"æ•°æ®æº: {self.stats['total_sources']} ä¸ªç±»åˆ«")
        logger.info(f"è¦†ç›–é“¾: {self.stats['active_chains']} æ¡")
        logger.info("=" * 60)
        
        # å¹¶å‘æ”¶é›†æ‰€æœ‰æ•°æ®
        tasks = [
            self.collect_all_chain_data(),
            self.collect_whale_data(),
            self.collect_social_sentiment(),
            self.collect_exchange_data(),
            self.collect_defi_ecosystem()
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # æ•´åˆæ•°æ®
        all_data = {
            "chain_data": results[0] if not isinstance(results[0], Exception) else {},
            "whale_data": results[1] if not isinstance(results[1], Exception) else {},
            "social_sentiment": results[2] if not isinstance(results[2], Exception) else {},
            "exchange_data": results[3] if not isinstance(results[3], Exception) else {},
            "defi_ecosystem": results[4] if not isinstance(results[4], Exception) else {}
        }
        
        # ç”Ÿæˆæƒ…æŠ¥æŠ¥å‘Š
        intelligence_report = await self.generate_intelligence_report(all_data)
        
        # è®°å½•ç»Ÿè®¡
        self.stats["data_points_per_minute"] = self.stats["api_calls_made"]
        
        logger.info(f"âœ… æ•°æ®æ”¶é›†å®Œæˆ")
        logger.info(f"APIè°ƒç”¨: {self.stats['api_calls_made']} æ¬¡")
        logger.info(f"é”™è¯¯: {self.stats['errors']} ä¸ª")
        logger.info(f"æ•°æ®å®Œæ•´åº¦: {intelligence_report['data_quality']['completeness']:.1%}")
        
        return intelligence_report


# æµ‹è¯•å‡½æ•°
async def test_ultimate_collector():
    """æµ‹è¯•ç»ˆææ•°æ®æ”¶é›†å™¨"""
    collector = UltimateDataCollector()
    
    print("\n" + "=" * 60)
    print("æµ‹è¯•Window 3 - ç»ˆææ•°æ®æ”¶é›†å™¨")
    print("=" * 60)
    
    # è¿è¡Œå®Œæ•´æ”¶é›†
    report = await collector.run_complete_collection()
    
    print("\nğŸ“Š æƒ…æŠ¥æŠ¥å‘Šæ‘˜è¦:")
    print(f"æŠ¥å‘ŠID: {report['report_id']}")
    print(f"å¸‚åœºæƒ…ç»ª: {report['market_overview']['sentiment']}")
    print(f"é£é™©ç­‰çº§: {report['market_overview']['risk_level']}")
    print(f"æ´»è·ƒé“¾: {len(report['onchain_activity']['active_chains'])} æ¡")
    print(f"æ•°æ®å®Œæ•´åº¦: {report['data_quality']['completeness']:.1%}")
    print(f"æ•°æ®å¯é æ€§: {report['data_quality']['reliability']:.1%}")
    
    if report['market_overview']['warnings']:
        print(f"\nâš ï¸ è­¦å‘Š:")
        for warning in report['market_overview']['warnings']:
            print(f"  - {warning}")
    
    print("\nâœ… æµ‹è¯•å®Œæˆï¼Window 3å·²å‡†å¤‡å¥½ä¸ºWindow 6æä¾›å…¨æ–¹ä½æƒ…æŠ¥æ”¯æŒ")


if __name__ == "__main__":
    asyncio.run(test_ultimate_collector())