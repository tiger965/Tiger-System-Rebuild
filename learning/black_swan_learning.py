"""
é»‘å¤©é¹…äº‹ä»¶å­¦ä¹ å·¥å…· - Window 9ç»„ä»¶
ä»å†å²é»‘å¤©é¹…äº‹ä»¶ä¸­å­¦ä¹ ï¼Œè¯†åˆ«ç›¸ä¼¼æ¨¡å¼
"""

import json
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional
import numpy as np
from collections import defaultdict


class BlackSwanLearning:
    """ä»å†å²é»‘å¤©é¹…äº‹ä»¶ä¸­å­¦ä¹ """
    
    def __init__(self, base_path: str = "learning_data"):
        """
        åˆå§‹åŒ–é»‘å¤©é¹…å­¦ä¹ å™¨
        
        Args:
            base_path: å­¦ä¹ æ•°æ®å­˜å‚¨åŸºç¡€è·¯å¾„
        """
        self.base_path = Path(base_path)
        self.patterns_path = self.base_path / "patterns"
        self.patterns_path.mkdir(parents=True, exist_ok=True)
        
        # å†å²é»‘å¤©é¹…äº‹ä»¶æ•°æ®åº“
        self.historical_events = self._init_historical_events()
        
        # æ¨¡å¼è¯†åˆ«é˜ˆå€¼
        self.similarity_threshold = 0.65
        
        # å½“å‰å¸‚åœºè­¦å‘Šçº§åˆ«
        self.warning_levels = {
            "LOW": 0.3,
            "MEDIUM": 0.5,
            "HIGH": 0.7,
            "CRITICAL": 0.9
        }
        
    def _init_historical_events(self) -> Dict:
        """åˆå§‹åŒ–å†å²é»‘å¤©é¹…äº‹ä»¶æ•°æ®"""
        return {
            "FTX_2022": {
                "date": "2022-11-08",
                "duration_days": 6,
                "max_drawdown": -0.98,
                "early_signals": [
                    "Alamedaèµ„äº§è´Ÿå€ºè¡¨æ³„éœ²",
                    "FTTä»£å¸å¤§é‡æŠ›å”®",
                    "å¸å®‰CEOå‘æ¨è´¨ç–‘",
                    "ç”¨æˆ·æç°æ¿€å¢",
                    "é“¾ä¸Šå¤§é¢è½¬ç§»å¼‚å¸¸"
                ],
                "cascade_speed": "6å¤©å½’é›¶",
                "affected_assets": ["FTT", "SOL", "SRM"],
                "lessons": [
                    "æµåŠ¨æ€§å±æœºä¿¡å·è¦ç«‹å³å“åº”",
                    "ä¸­å¿ƒåŒ–äº¤æ˜“æ‰€é£é™©éœ€è¦æŒç»­ç›‘æ§",
                    "å…³è”èµ„äº§ä¼šäº§ç”Ÿè¿é”ååº”"
                ],
                "opportunity": "åšç©ºFTTè·åˆ©500%+",
                "pattern_features": {
                    "liquidity_crisis": 1.0,
                    "regulatory_risk": 0.3,
                    "technical_failure": 0.1,
                    "market_manipulation": 0.6,
                    "cascade_effect": 0.9
                }
            },
            "LUNA_2022": {
                "date": "2022-05-07",
                "duration_days": 3,
                "max_drawdown": -0.999,
                "early_signals": [
                    "USTè½»å¾®è„±é”š",
                    "Curveæ± å¤±è¡¡",
                    "LFGå‚¨å¤‡è€—å°½",
                    "ææ…Œæ€§æŠ›å”®å¼€å§‹",
                    "æ­»äº¡èºæ—‹å½¢æˆ"
                ],
                "cascade_speed": "3å¤©å½’é›¶",
                "affected_assets": ["LUNA", "UST", "ANC", "MIR"],
                "lessons": [
                    "ç®—æ³•ç¨³å®šå¸è„±é”šé£é™©æé«˜",
                    "æ­»äº¡èºæ—‹ä¸€æ—¦å¼€å§‹éš¾ä»¥é€†è½¬",
                    "æ—©æœŸè„±é”šä¿¡å·å¿…é¡»é‡è§†"
                ],
                "opportunity": "åšç©ºLUNAè·åˆ©1000%+",
                "pattern_features": {
                    "liquidity_crisis": 0.7,
                    "regulatory_risk": 0.2,
                    "technical_failure": 0.9,
                    "market_manipulation": 0.4,
                    "cascade_effect": 1.0
                }
            },
            "312_2020": {
                "date": "2020-03-12",
                "duration_days": 1,
                "max_drawdown": -0.50,
                "early_signals": [
                    "ä¼ ç»Ÿå¸‚åœºææ…Œ",
                    "åŸæ²¹ä»·æ ¼æˆ˜",
                    "COVID-19å…¨çƒè”“å»¶",
                    "æµåŠ¨æ€§æ¯ç«­",
                    "è¿ç¯çˆ†ä»“"
                ],
                "cascade_speed": "24å°æ—¶è·Œ50%",
                "affected_assets": ["BTC", "ETH", "å…¨å¸‚åœº"],
                "lessons": [
                    "å¤–éƒ¨é»‘å¤©é¹…ä¼šä¼ å¯¼åˆ°åŠ å¯†å¸‚åœº",
                    "æµåŠ¨æ€§å±æœºå¯¼è‡´æ— å·®åˆ«æŠ›å”®",
                    "æç«¯ææ…Œæ˜¯æŠ„åº•è‰¯æœº"
                ],
                "opportunity": "3850ç¾å…ƒæŠ„åº•BTC",
                "pattern_features": {
                    "liquidity_crisis": 1.0,
                    "regulatory_risk": 0.0,
                    "technical_failure": 0.2,
                    "market_manipulation": 0.1,
                    "cascade_effect": 0.8
                }
            },
            "SVB_2023": {
                "date": "2023-03-10",
                "duration_days": 3,
                "max_drawdown": -0.25,
                "early_signals": [
                    "ç¡…è°·é“¶è¡ŒæŒ¤å…‘",
                    "USDCè„±é”š",
                    "é“¶è¡Œä¸šå±æœºè”“å»¶",
                    "ç›‘ç®¡ä»‹å…¥",
                    "ç¨³å®šå¸ä¿¡ä»»å±æœº"
                ],
                "cascade_speed": "3å¤©æ¢å¤",
                "affected_assets": ["USDC", "DAI", "FRAX"],
                "lessons": [
                    "ä¼ ç»Ÿé“¶è¡Œé£é™©ä¼šå½±å“ç¨³å®šå¸",
                    "ç›‘ç®¡ä»‹å…¥å¯å¿«é€Ÿç¨³å®šå¸‚åœº",
                    "è„±é”šå¯èƒ½æ˜¯æš‚æ—¶çš„"
                ],
                "opportunity": "USDC 0.87ç¾å…ƒæŠ„åº•",
                "pattern_features": {
                    "liquidity_crisis": 0.6,
                    "regulatory_risk": 0.8,
                    "technical_failure": 0.0,
                    "market_manipulation": 0.2,
                    "cascade_effect": 0.5
                }
            },
            "CELSIUS_2022": {
                "date": "2022-06-12",
                "duration_days": 30,
                "max_drawdown": -0.95,
                "early_signals": [
                    "æç°æš‚åœ",
                    "æµåŠ¨æ€§é—®é¢˜ä¼ é—»",
                    "CELä»£å¸å¼‚å¸¸æ³¢åŠ¨",
                    "å¤§æˆ·æ’¤èµ„",
                    "æ­»äº¡èºæ—‹é£é™©"
                ],
                "cascade_speed": "30å¤©ç ´äº§",
                "affected_assets": ["CEL", "å€Ÿè´·å¸‚åœº"],
                "lessons": [
                    "CeFiå¹³å°é£é™©ä¸å®¹å¿½è§†",
                    "é«˜æ”¶ç›ŠèƒŒåå¾€å¾€æ˜¯é«˜é£é™©",
                    "æç°é™åˆ¶æ˜¯é‡å¤§å±é™©ä¿¡å·"
                ],
                "opportunity": "æå‰æ’¤å‡ºèµ„é‡‘",
                "pattern_features": {
                    "liquidity_crisis": 0.9,
                    "regulatory_risk": 0.4,
                    "technical_failure": 0.1,
                    "market_manipulation": 0.3,
                    "cascade_effect": 0.6
                }
            }
        }
        
    def analyze_current_vs_historical(self, current_signals: List[str]) -> List[Dict]:
        """
        å¯¹æ¯”å½“å‰ä¿¡å·ä¸å†å²äº‹ä»¶
        
        Args:
            current_signals: å½“å‰å¸‚åœºä¿¡å·åˆ—è¡¨
            
        Returns:
            ç›¸ä¼¼åº¦åˆ†æç»“æœ
        """
        similarities = []
        
        for event_name, event_data in self.historical_events.items():
            similarity_score = self._calculate_similarity(current_signals, event_data)
            
            if similarity_score > self.similarity_threshold:
                similarities.append({
                    "event": event_name,
                    "date": event_data["date"],
                    "similarity": similarity_score,
                    "matched_signals": self._find_matched_signals(current_signals, event_data["early_signals"]),
                    "suggested_action": event_data.get("opportunity", ""),
                    "lessons": event_data["lessons"],
                    "risk_level": self._calculate_risk_level(similarity_score),
                    "cascade_speed": event_data["cascade_speed"],
                    "max_drawdown": event_data["max_drawdown"]
                })
                
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        similarities.sort(key=lambda x: x["similarity"], reverse=True)
        
        return similarities
        
    def _calculate_similarity(self, current_signals: List[str], event_data: Dict) -> float:
        """
        è®¡ç®—ä¿¡å·ç›¸ä¼¼åº¦
        
        Args:
            current_signals: å½“å‰ä¿¡å·
            event_data: å†å²äº‹ä»¶æ•°æ®
            
        Returns:
            ç›¸ä¼¼åº¦åˆ†æ•°(0-1)
        """
        if not current_signals:
            return 0.0
            
        historical_signals = event_data.get("early_signals", [])
        
        # åŸºäºå…³é”®è¯åŒ¹é…
        matched_count = 0
        for current in current_signals:
            current_lower = current.lower()
            for historical in historical_signals:
                historical_lower = historical.lower()
                
                # æ£€æŸ¥å…³é”®è¯åŒ¹é…
                if self._check_keyword_match(current_lower, historical_lower):
                    matched_count += 1
                    break
                    
        # è®¡ç®—åŸºç¡€ç›¸ä¼¼åº¦
        base_similarity = matched_count / max(len(historical_signals), len(current_signals))
        
        # è€ƒè™‘æ¨¡å¼ç‰¹å¾åŠ æƒ
        pattern_similarity = self._calculate_pattern_similarity(current_signals, event_data.get("pattern_features", {}))
        
        # ç»¼åˆç›¸ä¼¼åº¦
        final_similarity = base_similarity * 0.6 + pattern_similarity * 0.4
        
        return min(final_similarity, 1.0)
        
    def _check_keyword_match(self, signal1: str, signal2: str) -> bool:
        """æ£€æŸ¥å…³é”®è¯åŒ¹é…"""
        keywords = [
            "æµåŠ¨æ€§", "liquidity",
            "è„±é”š", "depeg",
            "çˆ†ä»“", "liquidation",
            "æŒ¤å…‘", "bank run",
            "ç ´äº§", "bankruptcy",
            "ç›‘ç®¡", "regulatory",
            "é»‘å®¢", "hack",
            "æ¼æ´", "exploit",
            "ææ…Œ", "panic",
            "æŠ›å”®", "sell-off",
            "æç°", "withdrawal",
            "æ­»äº¡èºæ—‹", "death spiral"
        ]
        
        for keyword in keywords:
            if keyword in signal1 and keyword in signal2:
                return True
                
        # æ¨¡ç³ŠåŒ¹é…
        words1 = set(signal1.split())
        words2 = set(signal2.split())
        
        # å¦‚æœæœ‰è¶…è¿‡30%çš„è¯åŒ¹é…ï¼Œè®¤ä¸ºç›¸ä¼¼
        if len(words1) > 0 and len(words2) > 0:
            intersection = words1.intersection(words2)
            match_ratio = len(intersection) / min(len(words1), len(words2))
            if match_ratio > 0.3:
                return True
                
        return False
        
    def _calculate_pattern_similarity(self, current_signals: List[str], pattern_features: Dict) -> float:
        """è®¡ç®—æ¨¡å¼ç‰¹å¾ç›¸ä¼¼åº¦"""
        current_features = self._extract_pattern_features(current_signals)
        
        if not pattern_features or not current_features:
            return 0.0
            
        # è®¡ç®—ç‰¹å¾å‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦
        similarity = 0.0
        total_weight = 0.0
        
        for feature, weight in pattern_features.items():
            if feature in current_features:
                similarity += weight * current_features[feature]
                total_weight += weight
                
        if total_weight > 0:
            return similarity / total_weight
            
        return 0.0
        
    def _extract_pattern_features(self, signals: List[str]) -> Dict:
        """ä»ä¿¡å·ä¸­æå–æ¨¡å¼ç‰¹å¾"""
        features = {
            "liquidity_crisis": 0.0,
            "regulatory_risk": 0.0,
            "technical_failure": 0.0,
            "market_manipulation": 0.0,
            "cascade_effect": 0.0
        }
        
        signal_text = " ".join(signals).lower()
        
        # æµåŠ¨æ€§å±æœºç‰¹å¾
        if any(word in signal_text for word in ["æµåŠ¨æ€§", "liquidity", "æç°", "withdrawal", "æŒ¤å…‘"]):
            features["liquidity_crisis"] = 0.8
            
        # ç›‘ç®¡é£é™©ç‰¹å¾
        if any(word in signal_text for word in ["ç›‘ç®¡", "regulatory", "SEC", "æ”¿ç­–", "ç¦ä»¤"]):
            features["regulatory_risk"] = 0.7
            
        # æŠ€æœ¯æ•…éšœç‰¹å¾
        if any(word in signal_text for word in ["é»‘å®¢", "hack", "æ¼æ´", "exploit", "æ•…éšœ", "bug"]):
            features["technical_failure"] = 0.8
            
        # å¸‚åœºæ“çºµç‰¹å¾
        if any(word in signal_text for word in ["æ“çºµ", "manipulation", "å·¨é²¸", "whale", "ç ¸ç›˜"]):
            features["market_manipulation"] = 0.6
            
        # çº§è”æ•ˆåº”ç‰¹å¾
        if any(word in signal_text for word in ["è¿é”", "cascade", "ä¼ æŸ“", "è”“å»¶", "èºæ—‹"]):
            features["cascade_effect"] = 0.7
            
        return features
        
    def _find_matched_signals(self, current_signals: List[str], historical_signals: List[str]) -> List[str]:
        """æ‰¾å‡ºåŒ¹é…çš„ä¿¡å·"""
        matched = []
        
        for current in current_signals:
            for historical in historical_signals:
                if self._check_keyword_match(current.lower(), historical.lower()):
                    matched.append(f"{current} â‰ˆ {historical}")
                    break
                    
        return matched
        
    def _calculate_risk_level(self, similarity: float) -> str:
        """è®¡ç®—é£é™©çº§åˆ«"""
        if similarity >= 0.9:
            return "CRITICAL"
        elif similarity >= 0.7:
            return "HIGH"
        elif similarity >= 0.5:
            return "MEDIUM"
        else:
            return "LOW"
            
    def has_similar_pattern(self, current_signal: Dict, historical_data: Dict) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦æœ‰ç›¸ä¼¼æ¨¡å¼
        
        Args:
            current_signal: å½“å‰ä¿¡å·
            historical_data: å†å²æ•°æ®
            
        Returns:
            æ˜¯å¦ç›¸ä¼¼
        """
        # æå–å½“å‰ä¿¡å·çš„ç‰¹å¾
        current_features = []
        
        if "signals" in current_signal:
            current_features = current_signal["signals"]
        elif "description" in current_signal:
            current_features = [current_signal["description"]]
            
        if not current_features:
            return False
            
        # è®¡ç®—ç›¸ä¼¼åº¦
        similarity = self._calculate_similarity(current_features, historical_data)
        
        return similarity > self.similarity_threshold
        
    def learn_from_new_event(self, event_data: Dict) -> bool:
        """
        ä»æ–°çš„é»‘å¤©é¹…äº‹ä»¶ä¸­å­¦ä¹ 
        
        Args:
            event_data: æ–°äº‹ä»¶æ•°æ®
            
        Returns:
            æ˜¯å¦æˆåŠŸæ·»åŠ 
        """
        event_name = event_data.get("name", f"Event_{datetime.now().strftime('%Y%m%d')}")
        
        # éªŒè¯å¿…è¦å­—æ®µ
        required_fields = ["date", "early_signals", "lessons", "max_drawdown"]
        for field in required_fields:
            if field not in event_data:
                print(f"ç¼ºå°‘å¿…è¦å­—æ®µ: {field}")
                return False
                
        # æ·»åŠ åˆ°å†å²äº‹ä»¶åº“
        self.historical_events[event_name] = event_data
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        self._save_events_database()
        
        return True
        
    def _save_events_database(self):
        """ä¿å­˜äº‹ä»¶æ•°æ®åº“"""
        db_path = self.patterns_path / "black_swan_events.json"
        with open(db_path, 'w', encoding='utf-8') as f:
            json.dump(self.historical_events, f, ensure_ascii=False, indent=2)
            
    def generate_risk_report(self, current_signals: List[str]) -> Dict:
        """
        ç”Ÿæˆé£é™©æŠ¥å‘Š
        
        Args:
            current_signals: å½“å‰å¸‚åœºä¿¡å·
            
        Returns:
            é£é™©æŠ¥å‘Š
        """
        similarities = self.analyze_current_vs_historical(current_signals)
        
        report = {
            "timestamp": datetime.now().isoformat(),
            "current_signals": current_signals,
            "risk_assessment": {
                "overall_risk": "LOW",
                "confidence": 0.0,
                "similar_events": [],
                "recommended_actions": []
            },
            "historical_matches": similarities[:3]  # æœ€ç›¸ä¼¼çš„3ä¸ªäº‹ä»¶
        }
        
        if similarities:
            # è®¡ç®—æ€»ä½“é£é™©
            max_similarity = similarities[0]["similarity"]
            
            if max_similarity >= 0.9:
                report["risk_assessment"]["overall_risk"] = "CRITICAL"
            elif max_similarity >= 0.7:
                report["risk_assessment"]["overall_risk"] = "HIGH"
            elif max_similarity >= 0.5:
                report["risk_assessment"]["overall_risk"] = "MEDIUM"
                
            report["risk_assessment"]["confidence"] = max_similarity
            
            # æå–è¡ŒåŠ¨å»ºè®®
            for event in similarities[:2]:
                if event["suggested_action"]:
                    report["risk_assessment"]["recommended_actions"].append(event["suggested_action"])
                    
                report["risk_assessment"]["similar_events"].append({
                    "event": event["event"],
                    "similarity": event["similarity"],
                    "lessons": event["lessons"]
                })
                
        return report


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    learner = BlackSwanLearning()
    
    # æ¨¡æ‹Ÿå½“å‰å¸‚åœºä¿¡å·
    current_signals = [
        "å¤§å‹äº¤æ˜“æ‰€æç°å»¶è¿Ÿ",
        "ç¨³å®šå¸å‡ºç°è½»å¾®è„±é”š",
        "é“¾ä¸Šå¤§é¢è½¬ç§»æ¿€å¢",
        "å¸‚åœºææ…Œæƒ…ç»ªä¸Šå‡",
        "æµåŠ¨æ€§æŒ‡æ ‡æ¶åŒ–"
    ]
    
    print("ğŸ¦¢ é»‘å¤©é¹…æ¨¡å¼åˆ†æ")
    print(f"å½“å‰ä¿¡å·: {current_signals}")
    
    # åˆ†æç›¸ä¼¼åº¦
    similarities = learner.analyze_current_vs_historical(current_signals)
    
    if similarities:
        print(f"\nâš ï¸ å‘ç°ç›¸ä¼¼å†å²äº‹ä»¶:")
        for sim in similarities[:3]:
            print(f"\näº‹ä»¶: {sim['event']}")
            print(f"ç›¸ä¼¼åº¦: {sim['similarity']:.1%}")
            print(f"é£é™©çº§åˆ«: {sim['risk_level']}")
            print(f"çº§è”é€Ÿåº¦: {sim['cascade_speed']}")
            print(f"æœ€å¤§å›æ’¤: {sim['max_drawdown']:.1%}")
            print(f"å»ºè®®è¡ŒåŠ¨: {sim['suggested_action']}")
            print(f"ç»éªŒæ•™è®­:")
            for lesson in sim['lessons']:
                print(f"  - {lesson}")
    else:
        print("\nâœ… æœªå‘ç°é«˜ç›¸ä¼¼åº¦å†å²äº‹ä»¶")
        
    # ç”Ÿæˆé£é™©æŠ¥å‘Š
    report = learner.generate_risk_report(current_signals)
    print(f"\nğŸ“Š é£é™©è¯„ä¼°æŠ¥å‘Š:")
    print(f"æ€»ä½“é£é™©: {report['risk_assessment']['overall_risk']}")
    print(f"ç½®ä¿¡åº¦: {report['risk_assessment']['confidence']:.1%}")
    if report['risk_assessment']['recommended_actions']:
        print(f"å»ºè®®è¡ŒåŠ¨:")
        for action in report['risk_assessment']['recommended_actions']:
            print(f"  - {action}")